---
title: "Bayes Final Project"
author: "Hannah Snell, Natalia Iannucci, Dianne Caravela, Elaine Ya"
date: "12/17/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(bayesrules)
library(rstan)
library(readr)
library(rstanarm)
library(bayesplot)
library(glmnet)
library(monomvn)
library(miscTools)
library(mice)
library(rstan)
library(modelr)
library(lars)

set.seed(84735)

timeone_clean <- read_csv("timeone_clean.csv")
```

# Select Variables

Data cleaning and imputation was moved to `data_cleaning.Rmd` file. 

```{r}
# covid <- read_csv("time1Time2Data.csv")
# time_1 <- read_csv("Sheet 1-Table 1-1.csv")
# time_1 <- time_1 %>%
#   filter(is.na(General_Health_Questionnaire_Negative_Total)==FALSE) %>%
#   filter(is.na(Age)==FALSE) %>%
#   filter(is.na(Gender)==FALSE) %>%
#   filter(is.na(Education)==FALSE) %>%
#   filter(is.na(Intolerance_of_Uncertainty_Total)==FALSE) %>%
#   filter(is.na(FFMQtotal)==FALSE) %>%
#   filter(is.na(Patient_Health_Questionnaire_Total)==FALSE) %>%
#   filter(is.na(Illnesses)==FALSE) %>%
#   filter(is.na(Perceived_Vulnerability_to_Disease_Total)==FALSE) %>%
#   filter(is.na(Perceived_susceptibility_COVID)==FALSE) %>%
#   filter(is.na(Annual_income)==FALSE) %>%
#   mutate(Employment_status_After_COVID = replace(Employment_status_After_COVID, Employment_status_After_COVID %in% c(4, 5, 6, 7), "unemployed")) %>%
#   mutate(Employment_status_After_COVID = replace(Employment_status_After_COVID, Employment_status_After_COVID %in% c(1,2), "parttime")) %>%
#   mutate(Employment_status_After_COVID = replace(Employment_status_After_COVID, Employment_status_After_COVID == 3, "fulltime")) %>%
#   mutate(Employment_status_After_COVID = replace(Employment_status_After_COVID, Employment_status_After_COVID == "unemployed", 0)) %>%
#   mutate(Employment_status_After_COVID = replace(Employment_status_After_COVID, Employment_status_After_COVID == "parttime", 1)) %>%
#   mutate(Employment_status_After_COVID = replace(Employment_status_After_COVID, Employment_status_After_COVID == "fulltime", 2)) %>%
#   mutate(Annual_income = log(Annual_income)) %>%
#   mutate(Marital_status = replace(Marital_status, Marital_status %in% c(1, 5, 6), 0)) %>%
#   mutate(Marital_status = replace(Marital_status, Marital_status %in% c(2, 3, 4), 1)) %>%
#   mutate(Illnesses = replace(Illnesses, Illnesses == 1, 0)) %>%
#   mutate(Illnesses = replace(Illnesses, Illnesses == 2, 1)) %>%
#   mutate(Gender = replace(Gender, Gender == 1, 0)) %>%
#   mutate(Gender = replace(Gender, Gender == 2, 1)) %>%
#   mutate(Isolation_yesorno = replace(Isolation_yesorno, Isolation_yesorno == 1, 0)) %>%
#   mutate(Isolation_yesorno = replace(Isolation_yesorno, Isolation_yesorno == 2, 1))
```

# Methods

## One for predicting quality of life (Association Model)

```{r}
timeone_clean <- read_csv("timeone_clean.csv")

timeone_rename <- timeone_clean %>%
  rename(FFMQ = FFMQtotal) %>%
  rename(PHQ = Patient_Health_Questionnaire_Total) %>%
  rename(GHQ = General_Health_Questionnaire_Negative_Total) %>%
  rename(PVD = Perceived_Vulnerability_to_Disease_Total) %>%
  rename(IUS = Intolerance_of_Uncertainty_Total) %>%
  rename(PPEuse = Preventive_Action_Taken_Scale_PPEuse_Total) %>%
  rename(QOL = Quality_of_Life_Total) %>%
  rename(income = Annual_income) %>%
  rename(Employment = Employment_status_After_COVID)

#THIS IS OUR FINAL MODEL! ((I Think at least...))
#for display purpose 
set.seed(84735)
mod_QOL_final_rename <- stan_glm(QOL ~ Age + as.factor(Gender) + Education + as.factor(Illnesses) + as.factor(Marital_status) + income + as.factor(Employment) + Isolation_yesorno + FFMQ,
                             data = timeone_rename,
                             family = gaussian,
                             chains = 4,
                             iter = 5000*2)

set.seed(84735)
mod_QOL_final <- stan_glm(Quality_of_Life_Total ~ Age + as.factor(Gender) + Education + as.factor(Marital_status) + Annual_income + as.factor(Employment_status_After_COVID) + Isolation_yesorno + FFMQtotal + as.factor(Illnesses),
                             data = timeone_clean,
                             family = gaussian,
                             chains = 4,
                             iter = 5000*2)
set.seed(84735)
pp_check(mod_QOL_final, nreps = 50)

set.seed(84735)
pp_check(mod_QOL_final_rename, nreps = 50)
mcmc_trace(mod_QOL_final_rename, size = 0.1)

mcmc_dens_overlay(mod_QOL_final_rename)
```

```{r}
model_summary_final <- summary(mod_QOL_final_rename)
mod_sum <- head(as.data.frame(model_summary_final), -2)

mod_sum

mod_table <- setNames(cbind(rownames(mod_sum), mod_sum, row.names=NULL), c("Variables", "mean", "mcse", "sd","10%", "50%", "90%", "n_eff","Rhat"))

#regression output table 
#mod_table <- mod_table %>%
#  mutate_each(funs(round(., 2)), -Variables) 
#write.table(mod_table, file = "mod_table.txt", sep = ",", quote = FALSE, row.names = F)

set.seed(84735)
cv <- prediction_summary_cv(
data = timeone_clean, model = mod_QOL_final, k = 10)

cv$cv

interval <- posterior_interval(mod_QOL_final_rename)
#output table with 90% credible interval 
mod_90_table <- mod_table %>%
  dplyr::select(-"10%",-"50%",-"90%") %>%
  cbind(data=interval) %>%
  mutate_each(funs(round(., 2)), -Variables) 
write.table(mod_90_table, file = "mod_90_table.txt", sep = ",", quote = FALSE, row.names = F)
```

```{r}
#M, SD, correlation table 
library(apaTables)
library(readr)
timeone_clean <- read_csv("timeone_clean.csv")
timeone_cor <- timeone_rename %>%
  dplyr::select(Age, income, FFMQ, IUS, PPEuse, QOL)

apa.cor.table(timeone_cor, filename = "correlation.doc", table.number = 1,
              show.conf.interval = F, landscape = TRUE)

# this plot is a bit ugly
timeone_cor %>%
  GGally::ggpairs()
```

## One for predicitng PPE use (Predictive Model)

### Using the LASSO Algorithm and Bayesian Regression to best predict PPE use! 

_Using the `monomvm` package for Bayesian Regression and LASSO:_ 

Before applying the model, I am assuming that we will need to do some sort of cross-validation, so I am going to split the dataset in half to make training and testing set for the algorithm:

```{r}
set.seed(84735)

samplesize <- 225

train_ind <- sample(nrow(timeone_clean), size = samplesize, replace = F, prob = NULL)

train <- timeone_clean[train_ind, ]
test <- timeone_clean[-train_ind, ] 

```

Time for Bayesian LASSO:

```{r, results = F}
# This chunk takes a bit of time to run
set.seed(84735)

# convert categorical vars to factors before putting them in the model: 
# train <- train %>% 
#   mutate(SOC_Category = as.factor(SOC_Category), 
#          State = as.factor(State), 
#          Religion = as.factor(Religion),
#          Preventive_Action_Taken_Scale_PPEuse_Total = as.factor(Preventive_Action_Taken_Scale_PPEuse_Total)) #%>% 
 #dplyr::select(-SOC_Category, -State, -Religion) # <- removing categorical vars in case they are causing the issue

# Define complicated model for model matrix: 
model_formula <-
  "Preventive_Action_Taken_Scale_PPEuse_Total ~ Age + Gender + SOC_Category_dummy + Religion_dummy + State_dummy + Employment_status_Befor_COVID + Employment_status_After_COVID + Marital_status + Education + Race + Annual_income + Illnesses + Meds + Accomodation + Isolation_yesorno + Isolation_number_of_days + Isolation_number_times_leave_per_day + Perceived_susceptibility_COVID + FFMQdescribetotal + FFMQnonreacttotal + FFMQnonjudgetotal + FFMQobservetotal + FFMQawaretotal + FFMQtotal + FFMQnonjudgemean + FFMQnonreactmean + FFMQobservemean + FFMQawaremean + FFMQdescribemean + Patient_Health_Questionnaire_Total + Quality_of_Life_Total + General_Health_Questionnaire_Negative_Total + Perceived_Vulnerability_to_Disease_Total + Intolerance_of_Uncertainty_Total + Preventive_Action_Taken_Scale_Avoid_Travel_People_Total + Impact_of_Events_Scale_Total + Number_of_children" %>%
  as.formula()

# Model matrix assembly for train data: 
x_matrix_train <- train %>%
  model_matrix(model_formula, data = .) %>%
  dplyr::select(-`(Intercept)`) %>%
  as.matrix()

x_matrix_test <- test %>%
  model_matrix(model_formula, data = .) %>%
  dplyr::select(-`(Intercept)`) %>%
  as.matrix()

# parameter setup
burnin <- 5000
iter <- 10000
initial.beta <- rep(-500, dim(x_matrix_train)[2]) # assigning an extreme initial value for all betas
initial.lambda2 <- 10 # assigning an extreme initial value for lambda (penalty parameter)
initial.variance <- 500 # assigning an extreme initial value for variance parameter

# starting the Gibbs sampler here
suppressWarnings(lasso <- blasso(X = x_matrix_train, # covariate matrix
                y = train$Preventive_Action_Taken_Scale_PPEuse_Total,  # response vector
                T = iter, # number of iterations
                beta = initial.beta, 
                lambda2 = initial.lambda2,  
                s2 = initial.variance))

# collecting draws for some of the parameters for quick check
coef.lasso <- as.data.frame(cbind(iter = seq(iter), 
                              beta1 = lasso$beta[, "b.1"], 
                              beta2 = lasso$beta[, "b.2"], 
                              variance = lasso$s2, 
                              lambda.square = lasso$lambda2))
```

```{r}
colMedians(coef.lasso[-seq(burnin), -1]) # new posterior median estimations
```

Median $\lambda.square$ value is 0.415044823 

#### Diagnostics: 

(The following results could be different if we specify our prior distributions instead of giving extreme values:) 

Comparing vars dumped in regular LASSO:

```{r}
# Compare regular LASSO vs. BLASSO: number of coefficients shrunk to zero 

# Regular LASSO
fit.glmnet <- glmnet(as.matrix(x_matrix_train), train$Preventive_Action_Taken_Scale_PPEuse_Total, 
                        lambda = cv.glmnet(as.matrix(x_matrix_train), train$Preventive_Action_Taken_Scale_PPEuse_Total)$lambda.1se)
coef.glmnet <- coef(fit.glmnet)
sum(coef.glmnet == 0)
# 32 vars dumped

# BLASSO
sum(colMedians(lasso$beta[-seq(burnin), ]) == 0)
# 31 vars dumped
```

```{r}
# made a results table based on nonzero slopes. 
coefficients <- tribble( 
  ~"var name", ~"beta", ~"median coef", ~"median tau2i", 
   "Age", "beta1", -0.0008406, 0.3313,
   "Religion_dummy", "beta4", -0.168963, 0.137869,
   "Marital_Status", "beta8", -0.00788, 0.3448, #fix these
   "Education", "beta9", 0.17121, 0.2283,
   "Intolerance_of_Uncertainty_Total", "beta35", 0.12965, 0.15457,
   "Preventive_Action_Taken_Scale_Avoid_Travel_People_Total", "beta36", 0.050522, 0.05764
  )
```

If we get that all of our betas are shrunken to zero, try tuning hyperparameters (Park & Casella, 2008).

More Diagnostics: 

```{r}
plot(lasso, burnin = 5000)

summary(lasso, burnin = 5000)
```

Cross Validation: 

```{r}
# cross-validation with lars package
cvlas <- cv.lars(x_matrix_train, train$Preventive_Action_Taken_Scale_PPEuse_Total, plot.it = TRUE, K = 10, type = "lasso")
```

```{r}
# overall plot of LASSO model
lasso.model <- lars(x = as.matrix(train[, colnames(train) != "Preventive_Action_Taken_Scale_PPEuse_Total"]), y = train$Preventive_Action_Taken_Scale_PPEuse_Total, 
    type = "lasso")

plot(lasso.model)
```


